{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_lang = 'en'\n",
    "target_lang = 'vi'\n",
    "data_dir = 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(folder=\"./data/\", rows=100000):\n",
    "    for file in os.listdir(folder):\n",
    "        file_path = os.path.join(os.path.abspath(folder), file)\n",
    "        if file_path.__contains__(\"train\"):\n",
    "            if file_path.endswith(source_lang):\n",
    "                file_en = open(file_path)\n",
    "                dataset_en = _read_file(file_en)\n",
    "            elif file_path.endswith(target_lang):\n",
    "                file_vi = open(file_path)\n",
    "                dataset_vi = _read_file(file_vi)\n",
    "    if rows != -1:\n",
    "        return [[dataset_en[i], dataset_vi[i]] for i in range(len(dataset_en))]\n",
    "    return dataset_en, dataset_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_file(file):\n",
    "\n",
    "    lines = file.readlines()\n",
    "    lst_lines = [x.strip() for x in lines]\n",
    "    return lst_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.DataFrame(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[corpus[0].map(len) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[corpus[1].map(len) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = '<start>'\n",
    "EOS_token = '<end>'\n",
    "UNK_token = '<unk>'\n",
    "PAD_token = '<pad>'\n",
    "\n",
    "SOS_idx = 0\n",
    "EOS_idx = 1\n",
    "UNK_idx = 2\n",
    "PAD_idx = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.index2word = {\n",
    "            SOS_idx: SOS_token,\n",
    "            EOS_idx: EOS_token,\n",
    "            UNK_idx: UNK_token,\n",
    "            PAD_idx: PAD_token\n",
    "        }\n",
    "        self.word2index = {v: k for k, v in self.index2word.items()}\n",
    "\n",
    "    def index_words(self, words):\n",
    "        for word in words:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            n_words = len(self)\n",
    "            self.word2index[word] = n_words\n",
    "            self.index2word[n_words] = word\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.index2word) == len(self.word2index)\n",
    "        return len(self.index2word)\n",
    "\n",
    "    def unidex_words(self, indices):\n",
    "        return [self.index2word[i] for i in indices]\n",
    "\n",
    "    def to_file(self, filename):\n",
    "        values = [w for w, k in sorted(list(self.word2index.items())[5:])]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('\\n'.join(values))\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, filename):\n",
    "        vocab = Vocab()\n",
    "        with open(filename, 'r') as f:\n",
    "            words = [l.strip() for l in f.readlines()]\n",
    "            vocab.index_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing complete\n",
      "vocab created\n",
      "vocab saved to file\n",
      "Corpus length: 133317\n",
      "Source vocabulary size: 42172\n",
      "Target vocabulary size: 19818\n",
      "Source: \"chronic pain is an example . if you burn yourself , you pull your hand away .\", target: \"đau kinh niên là một ví dụ . nếu bạn phỏng , bạn sẽ giật tay ra xa .\"\n",
      "Source: \"but if you & apos ; re still in pain in six months & apos ; or six years & apos ; time , it & apos ; s because these circuits are producing pain that & apos ; s no longer helping you .\", target: \"nhưng nếu trong sáu tháng , hay sáu năm , cơn đau vẫn không dứt , đó là vì những vòng tuần hoàn này đang sản xuất ra cơn đau chống lại bạn .\"\n",
      "Source: \"if we can look at the activation in the brain that & apos ; s producing the pain , we can form 3d models and watch in real time the brain process information , and then we can select the areas that produce the pain .\", target: \"nếu ta có thể nhìn vào các xung kích hoạt của não sản xuất ra cơn đau , ta có thể lập ra các mô hình 3 chiều và nhìn thấy các thông tin quá trình của não theo thời gian thực , chúng ta có thể lựa chọn vùng sản xuất cơn đau .\"\n",
      "Source: \"so put your arms back up and flex your bicep .\", target: \"vâng , hãy giơ tay lên và cong cơ cánh tay lại .\"\n",
      "Source: \"now imagine that you will soon be able to look inside your brain and select brain areas to do that same thing .\", target: \"bây giờ hãy tưởng tượng bạn sớm được nhìn vào bên trong não mình và được chọn vùng trên não để làm cùng một việc đó .\"\n",
      "Source: \"what you & apos ; re seeing here is , we & apos ; ve selected the pathways in the brain of a chronic pain patient .\", target: \"và điều bạn thấy là , chúng ta đã chọn đường đi trong não bộ của một bệnh nhân đau kinh niên .\"\n",
      "Source: \"this may shock you , but we & apos ; re literally reading this person & apos ; s brain in real time .\", target: \"điều này có thể làm bạn shock , nhưng thực sự chúng ta đã đọc được não bộ của người này theo thời gian thực .\"\n",
      "Source: \"they & apos ; re watching their own brain activation , and they & apos ; re controlling the pathway that produces their pain .\", target: \"họ đang theo dõi hoạt động não bộ của chính họ , và điều khiển con đường gây nên cơn đau .\"\n",
      "Source: \"they & apos ; re learning to flex this system that releases their own endogenous opiates .\", target: \"họ tập co dãn hệ thống tiết ra chất xoa dịu từ bên trong .\"\n",
      "Source: \"as they do it , in the upper left is a display that & apos ; s yoked to their brain activation of their own pain being controlled .\", target: \"khi họ làm vậy , ở góc trên bên trái ta thấy được thứ đã kết nối kích hoạt não bộ của cơn đau đang được điều khiển của họ .\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "max_length = 400\n",
    "min_word_count = 1\n",
    "\n",
    "tokenizers = {\n",
    "    'en': nltk.tokenize.WordPunctTokenizer().tokenize,\n",
    "    'vi': nltk.tokenize.WordPunctTokenizer().tokenize\n",
    "}\n",
    "\n",
    "def preprocess_corpus(sents, tokenizer, min_word_count):\n",
    "    n_words = {}\n",
    "\n",
    "    sents_tokenized = []\n",
    "    for sent in sents:\n",
    "        sent_tokenized = [w.lower() for w in tokenizer(sent)]\n",
    "\n",
    "        sents_tokenized.append(sent_tokenized)\n",
    "\n",
    "        for word in sent_tokenized:\n",
    "            if word in n_words:\n",
    "                n_words[word] += 1\n",
    "            else:\n",
    "                n_words[word] = 1\n",
    "\n",
    "    for i, sent_tokenized in enumerate(sents_tokenized):\n",
    "        sent_tokenized = [t if n_words[t] >= min_word_count else UNK_token for t in sent_tokenized]\n",
    "        sents_tokenized[i] = sent_tokenized\n",
    "\n",
    "    return sents_tokenized\n",
    "\n",
    "def read_vocab(sents):\n",
    "    vocab = Vocab()\n",
    "    for sent in sents:\n",
    "        vocab.index_words(sent)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "source_sents = preprocess_corpus(corpus[0], tokenizers[source_lang], min_word_count)\n",
    "target_sents = preprocess_corpus(corpus[1], tokenizers[target_lang], min_word_count)\n",
    "print(\"preprocessing complete\")\n",
    "\n",
    "source_vocab = read_vocab(source_sents)\n",
    "target_vocab = read_vocab(target_sents)\n",
    "print(\"vocab created\")\n",
    "target_vocab.to_file(os.path.join(data_dir, '{}.vocab.txt'.format(target_lang)))\n",
    "source_vocab.to_file(os.path.join(data_dir, '{}.vocab.txt'.format(source_lang)))\n",
    "print(\"vocab saved to file\")\n",
    "print('Corpus length: {}\\nSource vocabulary size: {}\\nTarget vocabulary size: {}'.format(\n",
    "    len(source_sents), len(source_vocab.word2index), len(target_vocab.word2index)\n",
    "))\n",
    "examples = list(zip(source_sents, target_sents))[80:90]\n",
    "for source, target in examples:\n",
    "    print('Source: \"{}\", target: \"{}\"'.format(' '.join(source), ' '.join(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "source_length = len(source_sents)\n",
    "inidices = np.random.permutation(source_length)\n",
    "\n",
    "training_indices = inidices[:int(source_length*0.94)]\n",
    "dev_indices = inidices[int(source_length*0.8):int(source_length*0.99)]\n",
    "test_indices = inidices[int(source_length*0.99):]\n",
    "\n",
    "training_source = [source_sents[i] for i in training_indices]\n",
    "dev_source = [source_sents[i] for i in dev_indices]\n",
    "test_source = [source_sents[i] for i in test_indices]\n",
    "\n",
    "training_target = [target_sents[i] for i in training_indices]\n",
    "dev_target = [target_sents[i] for i in dev_indices]\n",
    "test_target = [target_sents[i] for i in test_indices]\n",
    "\n",
    "# Unwrap training examples\n",
    "training_t = []\n",
    "training_s = []\n",
    "for source, tt in zip(training_source, training_target):\n",
    "    training_t.append(tt)\n",
    "    training_s.append(source)\n",
    "\n",
    "training_source = training_s\n",
    "training_target = training_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nên', 'trong', 'lúc', 'chúng', 'ta', 'đang', 'phải', 'đối', 'mặt', 'với', 'nhiều', 'cuộc', 'khủng', 'hoảng', 'cùng', 'một', 'lúc', 'trên', 'thế', 'giới', ',', 'điều', 'tốt', 'với', 'chúng', 'ta', 'trên', 'phương', 'diện', 'cá', 'nhân', ',', 'điều', 'mà', 'sẽ', 'đem', 'lại', 'cho', 'chúng', 'ta', 'niềm', 'vui', ',', 'lòng', 'biết', 'ơn', ',', 'hiệu', 'quả', 'trong', 'cuộc', 'sống', 'chúng', 'ta', 'và', 'sẽ', 'là', 'điều', 'tốt', 'nhất', 'đối', 'với', 'nghề', 'nghiệp', 'của', 'chính', 'chúng', 'ta', 'cũng', 'chính', 'là', 'điều', 'tốt', 'nhất', 'đối', 'với', 'thế', 'giới', '.']\n",
      "['so', 'as', 'we', 'are', 'facing', 'all', 'the', 'multiple', 'crises', 'in', 'our', 'world', 'at', 'the', 'moment', ',', 'what', 'is', 'good', 'for', 'us', 'on', 'a', 'personal', 'level', ',', 'what', '&', 'apos', ';', 's', 'going', 'to', 'bring', 'more', 'joy', ',', 'gratitude', ',', 'effectiveness', 'in', 'our', 'lives', 'and', 'be', 'the', 'best', 'for', 'our', 'own', 'careers', 'is', 'also', 'what', 'is', 'best', 'for', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "print(training_t[0])\n",
    "print(training_s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "def indexes_from_sentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "\n",
    "def tensor_from_sentence(vocab, sentence, max_seq_length):\n",
    "#     print(sentence)\n",
    "#     print(\"sentence over\")\n",
    "    indexes = indexes_from_sentence(vocab, sentence)\n",
    "    indexes.append(EOS_idx)\n",
    "    indexes.insert(0, SOS_idx)\n",
    "    # we need to have all sequences the same length to process them in batches\n",
    "    if len(indexes) < max_seq_length:\n",
    "        indexes += [PAD_idx] * (max_seq_length - len(indexes))\n",
    "    tensor = torch.LongTensor(indexes)\n",
    "    return tensor\n",
    "\n",
    "def tensors_from_pair(source_sent, target_sent, max_seq_length):\n",
    "    source_tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    target_tensor = tensor_from_sentence(target_vocab, target_sent, max_seq_length).unsqueeze(1)\n",
    "    return (source_tensor, target_tensor)\n",
    "\n",
    "max_seq_length = max_length + 2  # 2 for EOS_token and SOS_token\n",
    "\n",
    "training = []\n",
    "for source_sent, target_sent in zip(training_source, training_target):\n",
    "    training.append(tensors_from_pair(source_sent, target_sent, max_seq_length))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training, y_training = zip(*training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210\n",
      "1875\n",
      "37013\n",
      "53343\n",
      "55543\n",
      "61364\n",
      "73762\n",
      "82628\n",
      "83594\n"
     ]
    }
   ],
   "source": [
    "x_training = list(x_training)\n",
    "y_training = list(y_training)\n",
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(x_training)):\n",
    "    if x_training[i].size()[0] == 402:\n",
    "        new_x.append(x_training[i])\n",
    "        new_y.append(y_training[i])\n",
    "    else:\n",
    "        print(i)\n",
    "x_training = tuple(new_x)\n",
    "y_training = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24467\n"
     ]
    }
   ],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(dev_source)):\n",
    "    if len(dev_source[i]) <= 402:\n",
    "        new_x.append(dev_source[i])\n",
    "        new_y.append(dev_target[i])\n",
    "    else:\n",
    "        print(i)\n",
    "dev_source = tuple(new_x)\n",
    "dev_target = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56442\n",
      "76073\n",
      "104606\n",
      "114158\n"
     ]
    }
   ],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(y_training)):\n",
    "    if y_training[i].size()[0] == 402:\n",
    "        new_x.append(x_training[i])\n",
    "        new_y.append(y_training[i])\n",
    "    else:\n",
    "        print(i)\n",
    "x_training = tuple(new_x)\n",
    "y_training = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_training)):\n",
    "    if x_training[i].size()[0] != 402:\n",
    "        print(x_training[i].size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = torch.transpose(torch.cat(x_training, dim=-1), 1, 0)\n",
    "y_training = torch.transpose(torch.cat(y_training, dim=-1), 1, 0)\n",
    "torch.save(x_training, os.path.join(data_dir, 'x_training.bin'))\n",
    "torch.save(y_training, os.path.join(data_dir, 'y_training.bin'))\n",
    "\n",
    "x_development = []\n",
    "for source_sent in dev_source:\n",
    "    tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    x_development.append(tensor)\n",
    "\n",
    "x_development = torch.transpose(torch.cat(x_development, dim=-1), 1, 0)\n",
    "torch.save(x_development, os.path.join(data_dir, 'x_development.bin'))\n",
    "\n",
    "x_test = []\n",
    "for source_sent in test_source:\n",
    "    tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    x_test.append(tensor)\n",
    "\n",
    "x_test = torch.transpose(torch.cat(x_test, dim=-1), 1, 0)\n",
    "torch.save(x_test, os.path.join(data_dir, 'x_test.bin'))\n",
    "\n",
    "USE_CUDA = False\n",
    "if USE_CUDA:\n",
    "    x_training = x_training.cuda()\n",
    "    y_training = y_training.cuda()\n",
    "    x_development = x_development.cuda()\n",
    "    x_test = x_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        init.normal_(self.embedding.weight, 0.0, 0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            hidden_size,\n",
    "            int(hidden_size/2),  # Bi-directional processing will ouput vectors of double size, therefore I reduced output dimensionality\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,  # First dimension of input tensor will be treated as a batch dimension\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "    # word_inputs: (batch_size, seq_length), h: (h_or_c, layer_n_direction, batch, seq_length)\n",
    "    def forward(self, word_inputs, hidden):         \n",
    "        # embedded (batch_size, seq_length, hidden_size)\n",
    "        embedded = self.embedding(word_inputs)\n",
    "        # output (batch_size, seq_length, hidden_size*directions)\n",
    "        # hidden (h: (num_layers*directions, batch_size, hidden_size),\n",
    "        #         c: (num_layers*directions, batch_size, hidden_size))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batches):\n",
    "        hidden = torch.zeros(2, self.n_layers*2, batches, int(self.hidden_size/2))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        init.normal_(self.embedding.weight, 0.0, 0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=n_layers, batch_first=True, bidirectional=False)\n",
    "\n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this one by one\n",
    "        # embedded (batch_size, 1, hidden_size)\n",
    "        embedded = self.embedding(word_inputs).unsqueeze_(1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, hidden_size, n_layers):\n",
    "        super(Seq2seq, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.encoder = EncoderRNN(input_vocab_size, hidden_size, self.n_layers)\n",
    "        self.decoder = DecoderRNN(output_vocab_size, hidden_size, self.n_layers)\n",
    "\n",
    "        self.W = nn.Linear(hidden_size, output_vocab_size)\n",
    "        init.normal_(self.W.weight, 0.0, 0.2)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def _forward_encoder(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        init_hidden = self.encoder.init_hidden(batch_size)\n",
    "        encoder_outputs, encoder_hidden = self.encoder(x, init_hidden)\n",
    "        encoder_hidden_h, encoder_hidden_c = encoder_hidden\n",
    "\n",
    "        self.decoder_hidden_h = encoder_hidden_h.permute(1,0,2).reshape(batch_size, self.n_layers, self.hidden_size).permute(1,0,2)\n",
    "        self.decoder_hidden_c = encoder_hidden_c.permute(1,0,2).reshape(batch_size, self.n_layers, self.hidden_size).permute(1,0,2)\n",
    "        return self.decoder_hidden_h, self.decoder_hidden_c\n",
    "\n",
    "    def forward_train(self, x, y):\n",
    "        decoder_hidden_h, decoder_hidden_c = self._forward_encoder(x)\n",
    "\n",
    "        H = []\n",
    "        for i in range(y.shape[1]):\n",
    "            input = y[:, i]\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (batch_size, vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1))\n",
    "            # h: (batch_size, vocab_size, 1)\n",
    "            H.append(h.unsqueeze(2))\n",
    "\n",
    "        # H: (batch_size, vocab_size, seq_len)\n",
    "        return torch.cat(H, dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        decoder_hidden_h, decoder_hidden_c = self._forward_encoder(x)\n",
    "\n",
    "        current_y = SOS_idx\n",
    "        result = [current_y]\n",
    "        counter = 0\n",
    "        while current_y != EOS_idx and counter < 100:\n",
    "            input = torch.tensor([current_y])\n",
    "            decoder_output, decoder_hidden = self.decoder(input, (decoder_hidden_h, decoder_hidden_c))\n",
    "            decoder_hidden_h, decoder_hidden_c = decoder_hidden\n",
    "            # h: (vocab_size)\n",
    "            h = self.W(decoder_output.squeeze(1)).squeeze(0)\n",
    "            y = self.softmax(h)\n",
    "            _, current_y = torch.max(y, dim=0)\n",
    "            current_y = current_y.item()\n",
    "            result.append(current_y)\n",
    "            counter += 1\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = Seq2seq(len(source_vocab), len(target_vocab), 300, 1)\n",
    "optim = Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def batch_generator(batch_indices, batch_size):\n",
    "    batches = math.ceil(len(batch_indices)/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch_start = i*batch_size\n",
    "        batch_end = (i+1)*batch_size\n",
    "        if batch_end > len(batch_indices):\n",
    "            yield batch_indices[batch_start:]\n",
    "        else:\n",
    "            yield batch_indices[batch_start:batch_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def bleu(n):\n",
    "    weights = [1.0/n]*n + [0.0]*(4-n)\n",
    "    return lambda list_of_references, list_of_hypothesis: corpus_bleu(list_of_references, list_of_hypothesis, weights)\n",
    "\n",
    "def accuracy(list_of_references, list_of_hypothesis):\n",
    "    total = 0.0\n",
    "    for references, hypothesis in zip(list_of_references, list_of_hypothesis):\n",
    "        total += 1.0 if tuple(hypothesis) in set(references) else 0.0\n",
    "    return total / len(list_of_references)\n",
    "\n",
    "score_functions = {'BLEU-{}'.format(i):bleu(i) for i in range(1, 5)}\n",
    "score_functions['Accuracy'] = accuracy\n",
    "\n",
    "def score(model, X, target, desc='Scoring...'):\n",
    "    scores = {name:0.0 for name in score_functions.keys()}\n",
    "    length = len(target)\n",
    "    list_of_hypothesis = []\n",
    "    for i, x in tqdm(enumerate(X),\n",
    "                     desc=desc,\n",
    "                     total=length):\n",
    "        y = model(x.unsqueeze(0))\n",
    "        hypothesis = target_vocab.unidex_words(y[1:-1])  # Remove SOS and EOS from y\n",
    "        list_of_hypothesis.append(hypothesis)\n",
    "\n",
    "    for name, func in score_functions.items():\n",
    "        score = func(target, list_of_hypothesis)\n",
    "        scores[name] = score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f831bb4049744bc8881e2fc36b2184c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training epoch 1', max=1254, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9ad60deb814a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# (batch_size, vocab_size, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-dd277e679f60>\u001b[0m in \u001b[0;36mforward_train\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# H: (batch_size, vocab_size, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "total_batches = int(len(x_training)/BATCH_SIZE) + 1\n",
    "indices = list(range(len(x_training)))\n",
    "\n",
    "early_stop_after = 10\n",
    "early_stop_counter = 0\n",
    "best_model = None\n",
    "\n",
    "best_score = 0.0\n",
    "scoring_metric = 'BLEU-1'\n",
    "scores_history = []\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Training\n",
    "    total_loss = 0.0\n",
    "    for step, batch in tqdm(enumerate(batch_generator(indices, BATCH_SIZE)),\n",
    "                            desc='Training epoch {}'.format(epoch+1),\n",
    "                            total=total_batches):\n",
    "        x = x_training[batch, :]\n",
    "        # y for teacher forcing is all sequence without a last element\n",
    "        y_tf = y_training[batch, :-1]\n",
    "        # y for loss calculation is all sequence without a last element\n",
    "        y_true = y_training[batch, 1:]\n",
    "        # (batch_size, vocab_size, seq_length)\n",
    "        H = model.forward_train(x, y_tf)\n",
    "        loss = cross_entropy(H, y_true)\n",
    "\n",
    "        assert loss.item() > 0\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    loss_history.append(total_loss/total_batches)\n",
    "    print('Epoch {} training is finished, loss: {:.4f}'.format(epoch+1, total_loss/total_batches))\n",
    "\n",
    "    desc = 'Validating epoch {}'.format(epoch+1)\n",
    "    scores = score(model, x_development, dev_target, desc=desc)\n",
    "    scores_str = '\\n'.join(['{}: {:.4f}'.format(name, score) for name, score in scores.items()])\n",
    "    scores_history.append(scores)\n",
    "\n",
    "    print ('Epoch {} validation is finished.\\n{}'.format(\n",
    "        epoch+1, scores_str\n",
    "    ))\n",
    "\n",
    "    metric = scores[scoring_metric]\n",
    "\n",
    "    # Early Stop\n",
    "    if metric > best_score:\n",
    "        early_stop_counter = 0\n",
    "        print('The best model is found, resetting early stop counter.')\n",
    "        best_score = metric\n",
    "        best_model = model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print('No improvements for {} epochs.'.format(early_stop_counter))\n",
    "        if early_stop_counter >= early_stop_after:\n",
    "            print('Early stop!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

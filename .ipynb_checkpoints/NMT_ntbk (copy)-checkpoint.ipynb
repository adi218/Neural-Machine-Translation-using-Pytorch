{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "source_lang = 'en'\n",
    "target_lang = 'vi'\n",
    "data_dir = 'data/'\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(folder=\"./data/\", rows=100000):\n",
    "    for file in os.listdir(folder):\n",
    "        file_path = os.path.join(os.path.abspath(folder), file)\n",
    "        if file_path.__contains__(\"train\"):\n",
    "            if file_path.endswith(source_lang):\n",
    "                file_en = open(file_path)\n",
    "                dataset_en = _read_file(file_en)\n",
    "            elif file_path.endswith(target_lang):\n",
    "                file_vi = open(file_path)\n",
    "                dataset_vi = _read_file(file_vi)\n",
    "    if rows != -1:\n",
    "        return [[dataset_en[i], dataset_vi[i]] for i in range(len(dataset_en))]\n",
    "    return dataset_en, dataset_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_file(file):\n",
    "\n",
    "    lines = file.readlines()\n",
    "    lst_lines = [x.strip() for x in lines]\n",
    "    return lst_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.DataFrame(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[corpus[0].map(len) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[corpus[1].map(len) < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = '<start>'\n",
    "EOS_token = '<end>'\n",
    "UNK_token = '<unk>'\n",
    "PAD_token = '<pad>'\n",
    "\n",
    "SOS_idx = 0\n",
    "EOS_idx = 1\n",
    "UNK_idx = 2\n",
    "PAD_idx = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.index2word = {\n",
    "            SOS_idx: SOS_token,\n",
    "            EOS_idx: EOS_token,\n",
    "            UNK_idx: UNK_token,\n",
    "            PAD_idx: PAD_token\n",
    "        }\n",
    "        self.word2index = {v: k for k, v in self.index2word.items()}\n",
    "\n",
    "    def index_words(self, words):\n",
    "        for word in words:\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            n_words = len(self)\n",
    "            self.word2index[word] = n_words\n",
    "            self.index2word[n_words] = word\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.index2word) == len(self.word2index)\n",
    "        return len(self.index2word)\n",
    "\n",
    "    def unidex_words(self, indices):\n",
    "        return [self.index2word[i] for i in indices]\n",
    "\n",
    "    def to_file(self, filename):\n",
    "        values = [w for w, k in sorted(list(self.word2index.items())[5:])]\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('\\n'.join(values))\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, filename):\n",
    "        vocab = Vocab()\n",
    "        with open(filename, 'r') as f:\n",
    "            words = [l.strip() for l in f.readlines()]\n",
    "            vocab.index_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing complete\n",
      "vocab created\n",
      "vocab saved to file\n",
      "Corpus length: 133317\n",
      "Source vocabulary size: 42172\n",
      "Target vocabulary size: 19818\n",
      "Source: \"chronic pain is an example . if you burn yourself , you pull your hand away .\", target: \"đau kinh niên là một ví dụ . nếu bạn phỏng , bạn sẽ giật tay ra xa .\"\n",
      "Source: \"but if you & apos ; re still in pain in six months & apos ; or six years & apos ; time , it & apos ; s because these circuits are producing pain that & apos ; s no longer helping you .\", target: \"nhưng nếu trong sáu tháng , hay sáu năm , cơn đau vẫn không dứt , đó là vì những vòng tuần hoàn này đang sản xuất ra cơn đau chống lại bạn .\"\n",
      "Source: \"if we can look at the activation in the brain that & apos ; s producing the pain , we can form 3d models and watch in real time the brain process information , and then we can select the areas that produce the pain .\", target: \"nếu ta có thể nhìn vào các xung kích hoạt của não sản xuất ra cơn đau , ta có thể lập ra các mô hình 3 chiều và nhìn thấy các thông tin quá trình của não theo thời gian thực , chúng ta có thể lựa chọn vùng sản xuất cơn đau .\"\n",
      "Source: \"so put your arms back up and flex your bicep .\", target: \"vâng , hãy giơ tay lên và cong cơ cánh tay lại .\"\n",
      "Source: \"now imagine that you will soon be able to look inside your brain and select brain areas to do that same thing .\", target: \"bây giờ hãy tưởng tượng bạn sớm được nhìn vào bên trong não mình và được chọn vùng trên não để làm cùng một việc đó .\"\n",
      "Source: \"what you & apos ; re seeing here is , we & apos ; ve selected the pathways in the brain of a chronic pain patient .\", target: \"và điều bạn thấy là , chúng ta đã chọn đường đi trong não bộ của một bệnh nhân đau kinh niên .\"\n",
      "Source: \"this may shock you , but we & apos ; re literally reading this person & apos ; s brain in real time .\", target: \"điều này có thể làm bạn shock , nhưng thực sự chúng ta đã đọc được não bộ của người này theo thời gian thực .\"\n",
      "Source: \"they & apos ; re watching their own brain activation , and they & apos ; re controlling the pathway that produces their pain .\", target: \"họ đang theo dõi hoạt động não bộ của chính họ , và điều khiển con đường gây nên cơn đau .\"\n",
      "Source: \"they & apos ; re learning to flex this system that releases their own endogenous opiates .\", target: \"họ tập co dãn hệ thống tiết ra chất xoa dịu từ bên trong .\"\n",
      "Source: \"as they do it , in the upper left is a display that & apos ; s yoked to their brain activation of their own pain being controlled .\", target: \"khi họ làm vậy , ở góc trên bên trái ta thấy được thứ đã kết nối kích hoạt não bộ của cơn đau đang được điều khiển của họ .\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "max_length = 300\n",
    "min_word_count = 1\n",
    "\n",
    "tokenizers = {\n",
    "    'en': nltk.tokenize.WordPunctTokenizer().tokenize,\n",
    "    'vi': nltk.tokenize.WordPunctTokenizer().tokenize\n",
    "}\n",
    "\n",
    "def preprocess_corpus(sents, tokenizer, min_word_count):\n",
    "    n_words = {}\n",
    "\n",
    "    sents_tokenized = []\n",
    "    for sent in sents:\n",
    "        sent_tokenized = [w.lower() for w in tokenizer(sent)]\n",
    "\n",
    "        sents_tokenized.append(sent_tokenized)\n",
    "\n",
    "        for word in sent_tokenized:\n",
    "            if word in n_words:\n",
    "                n_words[word] += 1\n",
    "            else:\n",
    "                n_words[word] = 1\n",
    "\n",
    "    for i, sent_tokenized in enumerate(sents_tokenized):\n",
    "        sent_tokenized = [t if n_words[t] >= min_word_count else UNK_token for t in sent_tokenized]\n",
    "        sents_tokenized[i] = sent_tokenized\n",
    "\n",
    "    return sents_tokenized\n",
    "\n",
    "def read_vocab(sents):\n",
    "    vocab = Vocab()\n",
    "    for sent in sents:\n",
    "        vocab.index_words(sent)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "source_sents = preprocess_corpus(corpus[0], tokenizers[source_lang], min_word_count)\n",
    "target_sents = preprocess_corpus(corpus[1], tokenizers[target_lang], min_word_count)\n",
    "print(\"preprocessing complete\")\n",
    "\n",
    "source_vocab = read_vocab(source_sents)\n",
    "target_vocab = read_vocab(target_sents)\n",
    "print(\"vocab created\")\n",
    "target_vocab.to_file(os.path.join(data_dir, '{}.vocab.txt'.format(target_lang)))\n",
    "source_vocab.to_file(os.path.join(data_dir, '{}.vocab.txt'.format(source_lang)))\n",
    "print(\"vocab saved to file\")\n",
    "print('Corpus length: {}\\nSource vocabulary size: {}\\nTarget vocabulary size: {}'.format(\n",
    "    len(source_sents), len(source_vocab.word2index), len(target_vocab.word2index)\n",
    "))\n",
    "examples = list(zip(source_sents, target_sents))[80:90]\n",
    "for source, target in examples:\n",
    "    print('Source: \"{}\", target: \"{}\"'.format(' '.join(source), ' '.join(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "source_length = len(source_sents)\n",
    "inidices = np.random.permutation(source_length)\n",
    "\n",
    "training_indices = inidices[:int(source_length*0.94)]\n",
    "dev_indices = inidices[int(source_length*0.8):int(source_length*0.99)]\n",
    "test_indices = inidices[int(source_length*0.99):]\n",
    "\n",
    "training_source = [source_sents[i] for i in training_indices]\n",
    "dev_source = [source_sents[i] for i in dev_indices]\n",
    "test_source = [source_sents[i] for i in test_indices]\n",
    "\n",
    "training_target = [target_sents[i] for i in training_indices]\n",
    "dev_target = [target_sents[i] for i in dev_indices]\n",
    "test_target = [target_sents[i] for i in test_indices]\n",
    "\n",
    "# Unwrap training examples\n",
    "training_t = []\n",
    "training_s = []\n",
    "for source, tt in zip(training_source, training_target):\n",
    "    training_t.append(tt)\n",
    "    training_s.append(source)\n",
    "\n",
    "training_source = training_s\n",
    "training_target = training_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nên', 'trong', 'lúc', 'chúng', 'ta', 'đang', 'phải', 'đối', 'mặt', 'với', 'nhiều', 'cuộc', 'khủng', 'hoảng', 'cùng', 'một', 'lúc', 'trên', 'thế', 'giới', ',', 'điều', 'tốt', 'với', 'chúng', 'ta', 'trên', 'phương', 'diện', 'cá', 'nhân', ',', 'điều', 'mà', 'sẽ', 'đem', 'lại', 'cho', 'chúng', 'ta', 'niềm', 'vui', ',', 'lòng', 'biết', 'ơn', ',', 'hiệu', 'quả', 'trong', 'cuộc', 'sống', 'chúng', 'ta', 'và', 'sẽ', 'là', 'điều', 'tốt', 'nhất', 'đối', 'với', 'nghề', 'nghiệp', 'của', 'chính', 'chúng', 'ta', 'cũng', 'chính', 'là', 'điều', 'tốt', 'nhất', 'đối', 'với', 'thế', 'giới', '.']\n",
      "['so', 'as', 'we', 'are', 'facing', 'all', 'the', 'multiple', 'crises', 'in', 'our', 'world', 'at', 'the', 'moment', ',', 'what', 'is', 'good', 'for', 'us', 'on', 'a', 'personal', 'level', ',', 'what', '&', 'apos', ';', 's', 'going', 'to', 'bring', 'more', 'joy', ',', 'gratitude', ',', 'effectiveness', 'in', 'our', 'lives', 'and', 'be', 'the', 'best', 'for', 'our', 'own', 'careers', 'is', 'also', 'what', 'is', 'best', 'for', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "print(training_t[0])\n",
    "print(training_s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "def indexes_from_sentence(vocab, sentence):\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "\n",
    "def tensor_from_sentence(vocab, sentence, max_seq_length):\n",
    "#     print(sentence)\n",
    "#     print(\"sentence over\")\n",
    "    indexes = indexes_from_sentence(vocab, sentence)\n",
    "    indexes.append(EOS_idx)\n",
    "    indexes.insert(0, SOS_idx)\n",
    "    # we need to have all sequences the same length to process them in batches\n",
    "    if len(indexes) < max_seq_length:\n",
    "        indexes += [PAD_idx] * (max_seq_length - len(indexes))\n",
    "    tensor = torch.LongTensor(indexes)\n",
    "    return tensor\n",
    "\n",
    "def tensors_from_pair(source_sent, target_sent, max_seq_length):\n",
    "    source_tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    target_tensor = tensor_from_sentence(target_vocab, target_sent, max_seq_length).unsqueeze(1)\n",
    "    return (source_tensor, target_tensor)\n",
    "\n",
    "max_seq_length = max_length + 2  # 2 for EOS_token and SOS_token\n",
    "\n",
    "training = []\n",
    "for source_sent, target_sent in zip(training_source, training_target):\n",
    "    training.append(tensors_from_pair(source_sent, target_sent, max_seq_length))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training, y_training = zip(*training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210\n",
      "1875\n",
      "18451\n",
      "37013\n",
      "42232\n",
      "47921\n",
      "53343\n",
      "54855\n",
      "55543\n",
      "56447\n",
      "61364\n",
      "70397\n",
      "73762\n",
      "76080\n",
      "78750\n",
      "79818\n",
      "82628\n",
      "83594\n",
      "104615\n",
      "106694\n",
      "114167\n",
      "116373\n",
      "124865\n"
     ]
    }
   ],
   "source": [
    "x_training = list(x_training)\n",
    "y_training = list(y_training)\n",
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(x_training)):\n",
    "    if x_training[i].size()[0] == 302:\n",
    "        new_x.append(x_training[i])\n",
    "        new_y.append(y_training[i])\n",
    "    else:\n",
    "        print(i)\n",
    "x_training = tuple(new_x)\n",
    "y_training = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "7514\n",
      "9720\n",
      "18212\n",
      "24467\n"
     ]
    }
   ],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(dev_source)):\n",
    "    if len(dev_source[i]) <= 302:\n",
    "        new_x.append(dev_source[i])\n",
    "        new_y.append(dev_target[i])\n",
    "    else:\n",
    "        print(i)\n",
    "dev_source = tuple(new_x)\n",
    "dev_target = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4856\n",
      "15532\n",
      "19300\n",
      "32354\n",
      "57827\n"
     ]
    }
   ],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "for i in range(len(y_training)):\n",
    "    if y_training[i].size()[0] == 302:\n",
    "        new_x.append(x_training[i])\n",
    "        new_y.append(y_training[i])\n",
    "    else:\n",
    "        print(i)\n",
    "x_training = tuple(new_x)\n",
    "y_training = tuple(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_training)):\n",
    "    if x_training[i].size()[0] != 302:\n",
    "        print(x_training[i].size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = torch.transpose(torch.cat(x_training, dim=-1), 1, 0)\n",
    "y_training = torch.transpose(torch.cat(y_training, dim=-1), 1, 0)\n",
    "torch.save(x_training, os.path.join(data_dir, 'x_training.bin'))\n",
    "torch.save(y_training, os.path.join(data_dir, 'y_training.bin'))\n",
    "\n",
    "x_development = []\n",
    "for source_sent in dev_source:\n",
    "    tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    x_development.append(tensor)\n",
    "\n",
    "x_development = torch.transpose(torch.cat(x_development, dim=-1), 1, 0)\n",
    "torch.save(x_development, os.path.join(data_dir, 'x_development.bin'))\n",
    "\n",
    "x_test = []\n",
    "for source_sent in test_source:\n",
    "    tensor = tensor_from_sentence(source_vocab, source_sent, max_seq_length).unsqueeze(1)\n",
    "    x_test.append(tensor)\n",
    "\n",
    "x_test = torch.transpose(torch.cat(x_test, dim=-1), 1, 0)\n",
    "torch.save(x_test, os.path.join(data_dir, 'x_test.bin'))\n",
    "\n",
    "USE_CUDA = False\n",
    "if USE_CUDA:\n",
    "    x_training = x_training.cuda()\n",
    "    y_training = y_training.cuda()\n",
    "    x_development = x_development.cuda()\n",
    "    x_test = x_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = False\n",
    "device=\"cpu\"\n",
    "if USE_CUDA:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x_training = x_training.cuda()\n",
    "    y_training = y_training.cuda()\n",
    "    x_development = x_development.cuda()\n",
    "    x_test = x_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def batch_generator(batch_indices, batch_size):\n",
    "    batches = math.ceil(len(batch_indices)/batch_size)\n",
    "    for i in range(batches):\n",
    "        batch_start = i*batch_size\n",
    "        batch_end = (i+1)*batch_size\n",
    "        if batch_end > len(batch_indices):\n",
    "            yield batch_indices[batch_start:]\n",
    "        else:\n",
    "            yield batch_indices[batch_start:batch_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def bleu(n):\n",
    "    weights = [1.0/n]*n + [0.0]*(4-n)\n",
    "    return lambda list_of_references, list_of_hypothesis: corpus_bleu(list_of_references, list_of_hypothesis, weights)\n",
    "\n",
    "def accuracy(list_of_references, list_of_hypothesis):\n",
    "    total = 0.0\n",
    "    for references, hypothesis in zip(list_of_references, list_of_hypothesis):\n",
    "        total += 1.0 if tuple(hypothesis) in set(references) else 0.0\n",
    "    return total / len(list_of_references)\n",
    "\n",
    "score_functions = {'BLEU-{}'.format(i):bleu(i) for i in range(1, 5)}\n",
    "score_functions['Accuracy'] = accuracy\n",
    "\n",
    "def score(model, X, target, desc='Scoring...'):\n",
    "    scores = {name:0.0 for name in score_functions.keys()}\n",
    "    length = len(target)\n",
    "    list_of_hypothesis = []\n",
    "    for i, x in tqdm(enumerate(X),\n",
    "                     desc=desc,\n",
    "                     total=length):\n",
    "        y = model(x.unsqueeze(0))\n",
    "        hypothesis = target_vocab.unidex_words(y[1:-1])  # Remove SOS and EOS from y\n",
    "        list_of_hypothesis.append(hypothesis)\n",
    "\n",
    "    for name, func in score_functions.items():\n",
    "        score = func(target, list_of_hypothesis)\n",
    "        scores[name] = score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "total_batches = int(len(x_training)/BATCH_SIZE) + 1\n",
    "indices = list(range(len(x_training)))\n",
    "\n",
    "early_stop_after = 10\n",
    "early_stop_counter = 0\n",
    "best_model = None\n",
    "\n",
    "best_score = 0.0\n",
    "scoring_metric = 'BLEU-1'\n",
    "scores_history = []\n",
    "loss_history = []\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_length):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    print(input_tensor.size())\n",
    "    print(target_tensor.size())\n",
    "    print(\"ip length \", input_length)\n",
    "    print(\"tg length \", target_length)\n",
    "    encoder_outputs = torch.zeros(max_length+2, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_idx]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    input_tensors = [random.choice(x_training) for i in range(n_iters)]\n",
    "    target_tensors = [random.choice(y_training) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    print(len(input_tensors))\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        input_tensor = input_tensors[iter - 1]\n",
    "        print(input_tensor.size())\n",
    "        target_tensor = target_tensors[iter - 1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        print(loss)\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000\n",
      "torch.Size([302])\n",
      "torch.Size([302])\n",
      "torch.Size([302])\n",
      "ip length  302\n",
      "tg length  302\n",
      "9.778472294081126\n",
      "torch.Size([302])\n",
      "torch.Size([302])\n",
      "torch.Size([302])\n",
      "ip length  302\n",
      "tg length  302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-e0b5916a2826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-168-30ccb4ae1c2f>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m---> 20\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-b531285bdede>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mrequire\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0macceptable\u001b[0m \u001b[0mthen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mretain_graph\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfreed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnearly\u001b[0m \u001b[0mall\u001b[0m \u001b[0mcases\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0moption\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneeded\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moften\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mworked\u001b[0m \u001b[0maround\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(len(source_vocab), hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, len(target_vocab)).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)\n",
    "torch.save([encoder1,decoder1],'./model/nmt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
